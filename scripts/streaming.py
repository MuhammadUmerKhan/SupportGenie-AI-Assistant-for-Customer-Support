# Import BaseCallbackHandler from LangChain Core
from langchain_core.callbacks import BaseCallbackHandler

# Define a custom streaming handler that updates the UI in real-time
class StreamHandler(BaseCallbackHandler):
    
    def __init__(self, container, initial_text=""):
        """
        Initialize the StreamHandler.
        
        Args:
        - container: A Streamlit container (`st.empty()`) where the text will be displayed.
        - initial_text: The starting text for the container (default is an empty string).
        """
        self.container = container  # Store the Streamlit container
        self.text = initial_text  # Initialize the text storage

    def on_llm_new_token(self, token: str, **kwargs):
        """
        Callback method triggered when a new token is generated by the LLM.
        
        Args:
        - token: The new token generated by the LLM.
        - kwargs: Additional arguments (not used here).
        """
        self.text += token  # Append the new token to the existing text
        self.container.markdown(self.text)  # Update the Streamlit UI with the latest text
